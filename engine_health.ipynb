{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJeAkO_BiMcM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Predicting engine health/data/engine_data.csv')"
      ],
      "metadata": {
        "id": "tnBb4NDRiqFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "OOtnUkIyiuJ9",
        "outputId": "3f2c4fb8-44f1-4822-ba77-be4c82850fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Engine rpm  Lub oil pressure  Fuel pressure  Coolant pressure  \\\n",
              "0         700          2.493592      11.790927          3.178981   \n",
              "1         876          2.941606      16.193866          2.464504   \n",
              "2         520          2.961746       6.553147          1.064347   \n",
              "3         473          3.707835      19.510172          3.727455   \n",
              "4         619          5.672919      15.738871          2.052251   \n",
              "\n",
              "   lub oil temp  Coolant temp  Engine Condition  \n",
              "0     84.144163     81.632187                 1  \n",
              "1     77.640934     82.445724                 0  \n",
              "2     77.752266     79.645777                 1  \n",
              "3     74.129907     71.774629                 1  \n",
              "4     78.396989     87.000225                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a980834-5385-4b68-a1fd-2acd6951306f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engine rpm</th>\n",
              "      <th>Lub oil pressure</th>\n",
              "      <th>Fuel pressure</th>\n",
              "      <th>Coolant pressure</th>\n",
              "      <th>lub oil temp</th>\n",
              "      <th>Coolant temp</th>\n",
              "      <th>Engine Condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>700</td>\n",
              "      <td>2.493592</td>\n",
              "      <td>11.790927</td>\n",
              "      <td>3.178981</td>\n",
              "      <td>84.144163</td>\n",
              "      <td>81.632187</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>876</td>\n",
              "      <td>2.941606</td>\n",
              "      <td>16.193866</td>\n",
              "      <td>2.464504</td>\n",
              "      <td>77.640934</td>\n",
              "      <td>82.445724</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>520</td>\n",
              "      <td>2.961746</td>\n",
              "      <td>6.553147</td>\n",
              "      <td>1.064347</td>\n",
              "      <td>77.752266</td>\n",
              "      <td>79.645777</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>473</td>\n",
              "      <td>3.707835</td>\n",
              "      <td>19.510172</td>\n",
              "      <td>3.727455</td>\n",
              "      <td>74.129907</td>\n",
              "      <td>71.774629</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>619</td>\n",
              "      <td>5.672919</td>\n",
              "      <td>15.738871</td>\n",
              "      <td>2.052251</td>\n",
              "      <td>78.396989</td>\n",
              "      <td>87.000225</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a980834-5385-4b68-a1fd-2acd6951306f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a980834-5385-4b68-a1fd-2acd6951306f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a980834-5385-4b68-a1fd-2acd6951306f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.where(pd.isnull(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aivOH4lli6qk",
        "outputId": "f3858abe-a88b-4adf-ee30-3f13eef581a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxE1dmccjarG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IN terms of engine conditions, going to assume the value with the greatest frequency is considered 'normal' ie. not failing.\n",
        "\n",
        "Assuming 1 is 'normal'"
      ],
      "metadata": {
        "id": "MA7TDU-GlEtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Engine Condition'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASKSL5fblfjD",
        "outputId": "d001fc06-bcde-46a9-d74c-0024b49017c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12317\n",
              "0     7218\n",
              "Name: Engine Condition, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LPeDYLGamV7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WkTRViiKQo-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Designing a Hybrid LSTM-CNN Model to predict engine failure."
      ],
      "metadata": {
        "id": "qHBoSxvpQrcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a custom dataset class for loading the CSV data\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.features = self.data.drop('Engine Condition', axis=1).values\n",
        "        self.targets = self.data['Engine Condition'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.features[index]\n",
        "        y = self.targets[index]\n",
        "\n",
        "        # Convert the data to appropriate tensors\n",
        "        x = torch.from_numpy(x).float()\n",
        "        y = torch.tensor(y).long()\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# Define the file path for your data\n",
        "csv_file = '/content/drive/MyDrive/Predicting engine health/data/engine_data.csv'\n",
        "\n",
        "# Create an instance of the custom dataset\n",
        "dataset = CustomDataset(csv_file)\n",
        "\n",
        "# Define the hyperparameters and model architecture\n",
        "input_size = len(dataset.features[0])\n",
        "hidden_size = 64\n",
        "num_classes = 2\n",
        "\n",
        "# Set the random seed for reproducibility (optional)\n",
        "torch.manual_seed(17)\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "\n",
        "# Split the data into train and remaining data\n",
        "train_data, remaining_data = train_test_split(dataset, test_size=0.2, random_state=17)\n",
        "\n",
        "# Split the remaining data into validation and test sets\n",
        "val_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=17)\n",
        "\n",
        "# Create data loaders for training, validation, and testing sets\n",
        "batch_size =128\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the hybrid LSTM-CNN model\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
        "        self.cnn = nn.Conv1d(hidden_size, hidden_size, kernel_size=3)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_output, _ = self.lstm(x.unsqueeze(-1))\n",
        "        lstm_output = lstm_output.transpose(1, 2)\n",
        "        cnn_output = self.cnn(lstm_output)\n",
        "        cnn_output = torch.mean(cnn_output, dim=2)\n",
        "        output = self.fc(cnn_output)\n",
        "        return output\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 25\n",
        "\n",
        "# Check if a GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "#testing class\n",
        "\n",
        "class Tester:\n",
        "    def __init__(self, model, test_loader, criterion, device):\n",
        "        self.model = model\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_predictions = []\n",
        "        test_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in self.test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predictions = torch.max(outputs, 1)\n",
        "                test_predictions.extend(predictions.tolist())\n",
        "                test_targets.extend(targets.tolist())\n",
        "\n",
        "        test_loss /= len(self.test_loader.dataset)\n",
        "        test_accuracy = accuracy_score(test_targets, test_predictions)\n",
        "        test_precision = precision_score(test_targets, test_predictions, average='weighted')\n",
        "        test_recall = recall_score(test_targets, test_predictions, average='weighted')\n",
        "        test_f1 = f1_score(test_targets, test_predictions, average='weighted')\n",
        "        test_auc = roc_auc_score(test_targets, test_predictions)\n",
        "        test_cm = confusion_matrix(test_targets, test_predictions)\n",
        "\n",
        "        self.test_loss = test_loss\n",
        "        self.test_accuracy = test_accuracy\n",
        "        self.test_precision = test_precision\n",
        "        self.test_recall = test_recall\n",
        "        self.test_f1 = test_f1\n",
        "        self.test_auc = test_auc\n",
        "        self.test_cm = test_cm\n",
        "\n",
        "        print('Test Metrics:')\n",
        "        print(f'Loss: {test_loss:.4f}')\n",
        "        print(f'Accuracy: {test_accuracy:.4f}')\n",
        "        print(f'Precision: {test_precision:.4f}')\n",
        "        print(f'Recall: {test_recall:.4f}')\n",
        "        print(f'F1 Score: {test_f1:.4f}')\n",
        "        print(f'AUC: {test_auc:.4f}')\n",
        "        print('Confusion Matrix:')\n",
        "        print(test_cm)\n",
        "\n",
        "\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize lists to store the evaluation metrics for each fold\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_f1_scores = []\n",
        "val_aucs = []\n",
        "val_cms = []\n",
        "\n",
        "# Cross-validation loop\n",
        "for fold in range(num_folds):\n",
        "    print(f\"Fold [{fold + 1}/{num_folds}]\")\n",
        "\n",
        "    # Split the data into train and validation sets for the current fold\n",
        "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=fold)\n",
        "\n",
        "    # Create data loaders for the current fold\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize the model for the current fold\n",
        "    model = HybridModel(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "    # Set the number of epochs and early stopping criteria for the current fold\n",
        "    num_epochs = 13\n",
        "    early_stopping_counter = 0\n",
        "    early_stopping_threshold = 3\n",
        "    best_eval_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    # Define the optimizer for the current fold\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Training loop for the current fold\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # Set the model in training mode\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            # Move inputs and targets to the device (e.g., GPU)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate the loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Calculate the average training loss for the epoch\n",
        "        train_loss /= len(train_data)\n",
        "\n",
        "        # Evaluation loop for the current fold\n",
        "        eval_loss = 0.0\n",
        "        eval_predictions = []\n",
        "        eval_targets = []\n",
        "\n",
        "        # Set the model in evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                # Move inputs and targets to the device (e.g., GPU)\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Calculate the loss\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # Accumulate the loss\n",
        "                eval_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Get the predicted labels\n",
        "                _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "                # Collect the predictions and targets for evaluation metrics\n",
        "                eval_predictions.extend(predictions.tolist())\n",
        "                eval_targets.extend(targets.tolist())\n",
        "\n",
        "        # Calculate the average evaluation loss for the epoch\n",
        "        eval_loss /= len(val_data)\n",
        "\n",
        "        # Check if the current evaluation loss is the best so far\n",
        "        if eval_loss < best_eval_loss:\n",
        "            best_eval_loss = eval_loss\n",
        "            best_model = model.state_dict()\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        # Print the training and evaluation loss for the epoch\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {train_loss:.4f} - Evaluation Loss: {eval_loss:.4f}')\n",
        "\n",
        "        # Check if early stopping criteria are met\n",
        "        if early_stopping_counter >= early_stopping_threshold:\n",
        "            print(\"Early stopping triggered! No improvement seen for 3 epochs.\")\n",
        "            break\n",
        "\n",
        "    # Load the best model for the current fold\n",
        "    model.load_state_dict(best_model)\n",
        "\n",
        "    # Create a new data loader for the test set\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Create a tester instance for the current fold\n",
        "    tester = Tester(model, test_loader, criterion, device)\n",
        "\n",
        "    # Perform testing on the test set\n",
        "    tester.test()\n",
        "\n",
        "    # Store the evaluation metrics for the current fold\n",
        "    val_losses.append(eval_loss)\n",
        "    val_accuracies.append(tester.test_accuracy)\n",
        "    val_precisions.append(tester.test_precision)\n",
        "    val_recalls.append(tester.test_recall)\n",
        "    val_f1_scores.append(tester.test_f1)\n",
        "    val_aucs.append(tester.test_auc)\n",
        "    val_cms.append(tester.test_cm)\n",
        "\n",
        "# Calculate the average evaluation metrics across all folds\n",
        "avg_val_loss = np.mean(val_losses)\n",
        "avg_val_accuracy = np.mean(val_accuracies)\n",
        "avg_val_precision = np.mean(val_precisions)\n",
        "avg_val_recall = np.mean(val_recalls)\n",
        "avg_val_f1_score = np.mean(val_f1_scores)\n",
        "avg_val_auc = np.mean(val_aucs)\n",
        "avg_val_cm = np.mean(val_cms, axis=0)\n",
        "\n",
        "# Print the average evaluation metrics\n",
        "print('Average Validation Metrics:')\n",
        "print(f'Loss: {avg_val_loss:.4f}')\n",
        "print(f'Accuracy: {avg_val_accuracy:.4f}')\n",
        "print(f'Precision: {avg_val_precision:.4f}')\n",
        "print(f'Recall: {avg_val_recall:.4f}')\n",
        "print(f'F1 Score: {avg_val_f1_score:.4f}')\n",
        "print(f'AUC: {avg_val_auc:.4f}')\n",
        "print('Confusion Matrix:')\n",
        "print(avg_val_cm)\n",
        "\n",
        "# Now, perform testing on the test set using the best model\n",
        "# Create a new data loader for the test set\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create a tester instance for the final test\n",
        "final_tester = Tester(model, test_loader, criterion, device)\n",
        "\n",
        "# Perform testing on the test set\n",
        "final_tester.test()\n",
        "\n",
        "# Print the evaluation metrics on the test set\n",
        "print('Test Metrics:')\n",
        "print(f'Loss: {final_tester.test_loss:.4f}')\n",
        "print(f'Accuracy: {final_tester.test_accuracy:.4f}')\n",
        "print(f'Precision: {final_tester.test_precision:.4f}')\n",
        "print(f'Recall: {final_tester.test_recall:.4f}')\n",
        "print(f'F1 Score: {final_tester.test_f1:.4f}')\n",
        "print(f'AUC: {final_tester.test_auc:.4f}')\n",
        "print('Confusion Matrix:')\n",
        "print(final_tester.test_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5I9nugUj1LT",
        "outputId": "3cab8fc6-ccc7-4358-c031-670d0154ecc8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold [1/10]\n",
            "Epoch [1/13] - Training Loss: 0.6571 - Evaluation Loss: 0.6478\n",
            "Epoch [2/13] - Training Loss: 0.6458 - Evaluation Loss: 0.6270\n",
            "Epoch [3/13] - Training Loss: 0.6300 - Evaluation Loss: 0.6065\n",
            "Epoch [4/13] - Training Loss: 0.6145 - Evaluation Loss: 0.6668\n",
            "Epoch [5/13] - Training Loss: 0.6190 - Evaluation Loss: 0.6092\n",
            "Epoch [6/13] - Training Loss: 0.6114 - Evaluation Loss: 0.6057\n",
            "Epoch [7/13] - Training Loss: 0.6111 - Evaluation Loss: 0.6040\n",
            "Epoch [8/13] - Training Loss: 0.6123 - Evaluation Loss: 0.6055\n",
            "Epoch [9/13] - Training Loss: 0.6113 - Evaluation Loss: 0.6120\n",
            "Epoch [10/13] - Training Loss: 0.6122 - Evaluation Loss: 0.6005\n",
            "Epoch [11/13] - Training Loss: 0.6070 - Evaluation Loss: 0.6000\n",
            "Epoch [12/13] - Training Loss: 0.6109 - Evaluation Loss: 0.6013\n",
            "Epoch [13/13] - Training Loss: 0.6082 - Evaluation Loss: 0.5996\n",
            "Test Metrics:\n",
            "Loss: 0.5991\n",
            "Accuracy: 0.6781\n",
            "Precision: 0.6635\n",
            "Recall: 0.6781\n",
            "F1 Score: 0.6566\n",
            "AUC: 0.6134\n",
            "Confusion Matrix:\n",
            "[[ 266  449]\n",
            " [ 180 1059]]\n",
            "Fold [2/10]\n",
            "Epoch [1/13] - Training Loss: 0.6543 - Evaluation Loss: 0.6447\n",
            "Epoch [2/13] - Training Loss: 0.6458 - Evaluation Loss: 0.6414\n",
            "Epoch [3/13] - Training Loss: 0.6305 - Evaluation Loss: 0.6134\n",
            "Epoch [4/13] - Training Loss: 0.6154 - Evaluation Loss: 0.6241\n",
            "Epoch [5/13] - Training Loss: 0.6146 - Evaluation Loss: 0.6515\n",
            "Epoch [6/13] - Training Loss: 0.6106 - Evaluation Loss: 0.6075\n",
            "Epoch [7/13] - Training Loss: 0.6125 - Evaluation Loss: 0.6290\n",
            "Epoch [8/13] - Training Loss: 0.6107 - Evaluation Loss: 0.6370\n",
            "Epoch [9/13] - Training Loss: 0.6072 - Evaluation Loss: 0.6059\n",
            "Epoch [10/13] - Training Loss: 0.6068 - Evaluation Loss: 0.6066\n",
            "Epoch [11/13] - Training Loss: 0.6101 - Evaluation Loss: 0.6049\n",
            "Epoch [12/13] - Training Loss: 0.6093 - Evaluation Loss: 0.6090\n",
            "Epoch [13/13] - Training Loss: 0.6076 - Evaluation Loss: 0.6153\n",
            "Test Metrics:\n",
            "Loss: 0.6132\n",
            "Accuracy: 0.6602\n",
            "Precision: 0.6648\n",
            "Recall: 0.6602\n",
            "F1 Score: 0.6622\n",
            "AUC: 0.6404\n",
            "Confusion Matrix:\n",
            "[[405 310]\n",
            " [354 885]]\n",
            "Fold [3/10]\n",
            "Epoch [1/13] - Training Loss: 0.6458 - Evaluation Loss: 0.6318\n",
            "Epoch [2/13] - Training Loss: 0.6198 - Evaluation Loss: 0.6526\n",
            "Epoch [3/13] - Training Loss: 0.6134 - Evaluation Loss: 0.6060\n",
            "Epoch [4/13] - Training Loss: 0.6132 - Evaluation Loss: 0.6063\n",
            "Epoch [5/13] - Training Loss: 0.6168 - Evaluation Loss: 0.6058\n",
            "Epoch [6/13] - Training Loss: 0.6129 - Evaluation Loss: 0.6132\n",
            "Epoch [7/13] - Training Loss: 0.6103 - Evaluation Loss: 0.6086\n",
            "Epoch [8/13] - Training Loss: 0.6116 - Evaluation Loss: 0.6055\n",
            "Epoch [9/13] - Training Loss: 0.6121 - Evaluation Loss: 0.6067\n",
            "Epoch [10/13] - Training Loss: 0.6065 - Evaluation Loss: 0.6045\n",
            "Epoch [11/13] - Training Loss: 0.6096 - Evaluation Loss: 0.6229\n",
            "Epoch [12/13] - Training Loss: 0.6098 - Evaluation Loss: 0.6067\n",
            "Epoch [13/13] - Training Loss: 0.6090 - Evaluation Loss: 0.6055\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.5997\n",
            "Accuracy: 0.6730\n",
            "Precision: 0.6619\n",
            "Recall: 0.6730\n",
            "F1 Score: 0.6285\n",
            "AUC: 0.5854\n",
            "Confusion Matrix:\n",
            "[[ 185  530]\n",
            " [ 109 1130]]\n",
            "Fold [4/10]\n",
            "Epoch [1/13] - Training Loss: 0.6470 - Evaluation Loss: 0.6224\n",
            "Epoch [2/13] - Training Loss: 0.6189 - Evaluation Loss: 0.6191\n",
            "Epoch [3/13] - Training Loss: 0.6120 - Evaluation Loss: 0.6066\n",
            "Epoch [4/13] - Training Loss: 0.6152 - Evaluation Loss: 0.6077\n",
            "Epoch [5/13] - Training Loss: 0.6087 - Evaluation Loss: 0.6121\n",
            "Epoch [6/13] - Training Loss: 0.6109 - Evaluation Loss: 0.6086\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.6024\n",
            "Accuracy: 0.6740\n",
            "Precision: 0.6643\n",
            "Recall: 0.6740\n",
            "F1 Score: 0.6282\n",
            "AUC: 0.5853\n",
            "Confusion Matrix:\n",
            "[[ 182  533]\n",
            " [ 104 1135]]\n",
            "Fold [5/10]\n",
            "Epoch [1/13] - Training Loss: 0.6529 - Evaluation Loss: 0.6359\n",
            "Epoch [2/13] - Training Loss: 0.6252 - Evaluation Loss: 0.6072\n",
            "Epoch [3/13] - Training Loss: 0.6151 - Evaluation Loss: 0.6202\n",
            "Epoch [4/13] - Training Loss: 0.6174 - Evaluation Loss: 0.6026\n",
            "Epoch [5/13] - Training Loss: 0.6124 - Evaluation Loss: 0.6054\n",
            "Epoch [6/13] - Training Loss: 0.6159 - Evaluation Loss: 0.5993\n",
            "Epoch [7/13] - Training Loss: 0.6168 - Evaluation Loss: 0.6045\n",
            "Epoch [8/13] - Training Loss: 0.6125 - Evaluation Loss: 0.6035\n",
            "Epoch [9/13] - Training Loss: 0.6112 - Evaluation Loss: 0.6020\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.6030\n",
            "Accuracy: 0.6760\n",
            "Precision: 0.6643\n",
            "Recall: 0.6760\n",
            "F1 Score: 0.6368\n",
            "AUC: 0.5928\n",
            "Confusion Matrix:\n",
            "[[ 202  513]\n",
            " [ 120 1119]]\n",
            "Fold [6/10]\n",
            "Epoch [1/13] - Training Loss: 0.6544 - Evaluation Loss: 0.6491\n",
            "Epoch [2/13] - Training Loss: 0.6363 - Evaluation Loss: 0.6323\n",
            "Epoch [3/13] - Training Loss: 0.6149 - Evaluation Loss: 0.6375\n",
            "Epoch [4/13] - Training Loss: 0.6133 - Evaluation Loss: 0.6100\n",
            "Epoch [5/13] - Training Loss: 0.6109 - Evaluation Loss: 0.6289\n",
            "Epoch [6/13] - Training Loss: 0.6090 - Evaluation Loss: 0.6154\n",
            "Epoch [7/13] - Training Loss: 0.6119 - Evaluation Loss: 0.6342\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.6228\n",
            "Accuracy: 0.6361\n",
            "Precision: 0.6017\n",
            "Recall: 0.6361\n",
            "F1 Score: 0.5181\n",
            "AUC: 0.5102\n",
            "Confusion Matrix:\n",
            "[[  29  686]\n",
            " [  25 1214]]\n",
            "Fold [7/10]\n",
            "Epoch [1/13] - Training Loss: 0.6524 - Evaluation Loss: 0.6476\n",
            "Epoch [2/13] - Training Loss: 0.6258 - Evaluation Loss: 0.6244\n",
            "Epoch [3/13] - Training Loss: 0.6110 - Evaluation Loss: 0.6209\n",
            "Epoch [4/13] - Training Loss: 0.6147 - Evaluation Loss: 0.6271\n",
            "Epoch [5/13] - Training Loss: 0.6105 - Evaluation Loss: 0.6167\n",
            "Epoch [6/13] - Training Loss: 0.6099 - Evaluation Loss: 0.6089\n",
            "Epoch [7/13] - Training Loss: 0.6078 - Evaluation Loss: 0.6112\n",
            "Epoch [8/13] - Training Loss: 0.6086 - Evaluation Loss: 0.6203\n",
            "Epoch [9/13] - Training Loss: 0.6074 - Evaluation Loss: 0.6205\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.6079\n",
            "Accuracy: 0.6643\n",
            "Precision: 0.6583\n",
            "Recall: 0.6643\n",
            "F1 Score: 0.5999\n",
            "AUC: 0.5628\n",
            "Confusion Matrix:\n",
            "[[ 132  583]\n",
            " [  73 1166]]\n",
            "Fold [8/10]\n",
            "Epoch [1/13] - Training Loss: 0.6582 - Evaluation Loss: 0.6434\n",
            "Epoch [2/13] - Training Loss: 0.6305 - Evaluation Loss: 0.6217\n",
            "Epoch [3/13] - Training Loss: 0.6135 - Evaluation Loss: 0.6268\n",
            "Epoch [4/13] - Training Loss: 0.6167 - Evaluation Loss: 0.6048\n",
            "Epoch [5/13] - Training Loss: 0.6137 - Evaluation Loss: 0.6111\n",
            "Epoch [6/13] - Training Loss: 0.6117 - Evaluation Loss: 0.6230\n",
            "Epoch [7/13] - Training Loss: 0.6176 - Evaluation Loss: 0.6045\n",
            "Epoch [8/13] - Training Loss: 0.6137 - Evaluation Loss: 0.6048\n",
            "Epoch [9/13] - Training Loss: 0.6080 - Evaluation Loss: 0.6045\n",
            "Epoch [10/13] - Training Loss: 0.6109 - Evaluation Loss: 0.6188\n",
            "Epoch [11/13] - Training Loss: 0.6092 - Evaluation Loss: 0.6011\n",
            "Epoch [12/13] - Training Loss: 0.6083 - Evaluation Loss: 0.6090\n",
            "Epoch [13/13] - Training Loss: 0.6079 - Evaluation Loss: 0.6024\n",
            "Test Metrics:\n",
            "Loss: 0.6017\n",
            "Accuracy: 0.6791\n",
            "Precision: 0.6649\n",
            "Recall: 0.6791\n",
            "F1 Score: 0.6593\n",
            "AUC: 0.6165\n",
            "Confusion Matrix:\n",
            "[[ 274  441]\n",
            " [ 186 1053]]\n",
            "Fold [9/10]\n",
            "Epoch [1/13] - Training Loss: 0.6451 - Evaluation Loss: 0.6269\n",
            "Epoch [2/13] - Training Loss: 0.6205 - Evaluation Loss: 0.6028\n",
            "Epoch [3/13] - Training Loss: 0.6135 - Evaluation Loss: 0.6073\n",
            "Epoch [4/13] - Training Loss: 0.6124 - Evaluation Loss: 0.6195\n",
            "Epoch [5/13] - Training Loss: 0.6095 - Evaluation Loss: 0.6112\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.6101\n",
            "Accuracy: 0.6668\n",
            "Precision: 0.6607\n",
            "Recall: 0.6668\n",
            "F1 Score: 0.6064\n",
            "AUC: 0.5678\n",
            "Confusion Matrix:\n",
            "[[ 142  573]\n",
            " [  78 1161]]\n",
            "Fold [10/10]\n",
            "Epoch [1/13] - Training Loss: 0.6540 - Evaluation Loss: 0.6521\n",
            "Epoch [2/13] - Training Loss: 0.6369 - Evaluation Loss: 0.6204\n",
            "Epoch [3/13] - Training Loss: 0.6227 - Evaluation Loss: 0.6027\n",
            "Epoch [4/13] - Training Loss: 0.6157 - Evaluation Loss: 0.6163\n",
            "Epoch [5/13] - Training Loss: 0.6131 - Evaluation Loss: 0.5994\n",
            "Epoch [6/13] - Training Loss: 0.6100 - Evaluation Loss: 0.5964\n",
            "Epoch [7/13] - Training Loss: 0.6112 - Evaluation Loss: 0.5981\n",
            "Epoch [8/13] - Training Loss: 0.6116 - Evaluation Loss: 0.6020\n",
            "Epoch [9/13] - Training Loss: 0.6135 - Evaluation Loss: 0.6054\n",
            "Early stopping triggered! No improvement seen for 3 epochs.\n",
            "Test Metrics:\n",
            "Loss: 0.6088\n",
            "Accuracy: 0.6786\n",
            "Precision: 0.6655\n",
            "Recall: 0.6786\n",
            "F1 Score: 0.6643\n",
            "AUC: 0.6238\n",
            "Confusion Matrix:\n",
            "[[ 300  415]\n",
            " [ 213 1026]]\n",
            "Average Validation Metrics:\n",
            "Loss: 0.6105\n",
            "Accuracy: 0.6686\n",
            "Precision: 0.6570\n",
            "Recall: 0.6686\n",
            "F1 Score: 0.6260\n",
            "AUC: 0.5898\n",
            "Confusion Matrix:\n",
            "[[ 211.7  503.3]\n",
            " [ 144.2 1094.8]]\n",
            "Test Metrics:\n",
            "Loss: 0.6088\n",
            "Accuracy: 0.6786\n",
            "Precision: 0.6655\n",
            "Recall: 0.6786\n",
            "F1 Score: 0.6643\n",
            "AUC: 0.6238\n",
            "Confusion Matrix:\n",
            "[[ 300  415]\n",
            " [ 213 1026]]\n",
            "Test Metrics:\n",
            "Loss: 0.6088\n",
            "Accuracy: 0.6786\n",
            "Precision: 0.6655\n",
            "Recall: 0.6786\n",
            "F1 Score: 0.6643\n",
            "AUC: 0.6238\n",
            "Confusion Matrix:\n",
            "[[ 300  415]\n",
            " [ 213 1026]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYG5jYr6sqr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}